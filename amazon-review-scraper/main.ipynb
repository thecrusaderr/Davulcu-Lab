{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "import os\n",
    "from playwright.async_api import async_playwright\n",
    "import time\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurations\n",
    "amazon_home = \"https://www.amazon.com/\"\n",
    "products_to_search = ['Huggies diapers']\n",
    "\n",
    "\n",
    "# products_to_search = ['hello bello diapers', 'pampers diapers', 'Huggies diapers', 'Dyper diapers', 'pura diapers', 'parasol diapers', 'Believe Baby diapers', 'Believe Baby diapers', 'Millie moon diapers', 'rascal diapers']\n",
    "\n",
    "# pampers - 6134\n",
    "# Huggies - 3382\n",
    "# Dyper - 1216\n",
    "# pura - 1232\n",
    "# parasol - 246\n",
    "# Believe Baby - 64\n",
    "# Millie moon - 34\n",
    "# rascal - 2\n",
    "# , 'MyPura', 'Rascals', 'believe baby', 'parasol', 'millie moon', 'ecoiginals', 'everylife', 'dyper'\n",
    "max_items = 20 # if product name is given, this is the maximum number of items to search for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load environment variables\n",
    "env = dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response url='https://www.amazon.com/' request=<Request url='https://www.amazon.com/' method='GET'>>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Launch Browser\n",
    "async def start_browser():\n",
    "    p = await async_playwright().start()\n",
    "    browser = await p.chromium.launch(\n",
    "        headless=False\n",
    "        # executable_path=\"/Users/sahilhadke/Library/Caches/ms-playwright/firefox-1471/firefox/firefox\"\n",
    "    )\n",
    "    context = await browser.new_context()\n",
    "    page = await context.new_page()\n",
    "    return p, browser, context, page\n",
    "\n",
    "# Execute this block to start the browser\n",
    "p, browser, context, page = await start_browser()\n",
    "await page.goto(amazon_home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login Manually\n",
    "async def login():\n",
    "    # click on sign in button\n",
    "    sign_in_button = await page.wait_for_selector(\"//a[@data-nav-role='signin']\")\n",
    "    await sign_in_button.click()\n",
    "\n",
    "    # enter email\n",
    "    email_input = await page.wait_for_selector(\"input[type='email']\")\n",
    "    await email_input.fill(os.getenv(\"AMAZON_EMAIL\"))\n",
    "\n",
    "    # click on continue\n",
    "    continue_button = await page.wait_for_selector(\"//span[@id='continue']//input\")\n",
    "\n",
    "    # click on continue\n",
    "    await continue_button.click()\n",
    "\n",
    "    # enter password\n",
    "    password_input = await page.wait_for_selector(\"input[type='password']\")\n",
    "    await password_input.fill(os.getenv(\"AMAZON_PASSWORD\"))\n",
    "\n",
    "    # click on sign in\n",
    "    sign_in_button = await page.wait_for_selector(\"//input[@id='signInSubmit']\")\n",
    "    await sign_in_button.click()\n",
    "\n",
    "# Execute this block to login\n",
    "await login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create output json file\n",
    "def save_reviews(reviews, filename=f\"reviews.json\"):\n",
    "    \"\"\"Save reviews to JSON file after every 50 reviews.\"\"\"\n",
    "    if os.path.exists(filename):\n",
    "        with open(filename, \"r\") as file:\n",
    "            try:\n",
    "                existing_data = json.load(file)\n",
    "            except json.JSONDecodeError:\n",
    "                existing_data = {}\n",
    "    else:\n",
    "        existing_data = {}\n",
    "\n",
    "    existing_data.update(reviews)  # Append new reviews to existing data\n",
    "\n",
    "    with open(filename, \"w\") as file:\n",
    "        json.dump(existing_data, file, indent=4)\n",
    "        \n",
    "async def get_reviews(url, product_keyword=''):\n",
    "    stars_to_scrape = 1\n",
    "    review_dictionary = {}\n",
    "\n",
    "    await page.goto(url)\n",
    "\n",
    "    # Get product name\n",
    "    product_name = await page.query_selector(\"span#productTitle\")\n",
    "    product_name = await product_name.inner_text() if product_name else \"\"\n",
    "\n",
    "    review_dictionary[\"product_name\"] = product_name\n",
    "    review_dictionary[\"url\"] = url.split(\"?\")[0]\n",
    "\n",
    "    if product_keyword != '' and product_keyword.lower() not in product_name.lower():\n",
    "        return review_dictionary\n",
    "\n",
    "    print(f\"Product Name = {product_name}\")\n",
    "\n",
    "    # Scroll to Reviews Section\n",
    "    for _ in range(20):\n",
    "        await page.evaluate(\"window.scrollBy(0, 1000)\")\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        review_more_link = await page.query_selector(\"//a[@data-hook='see-all-reviews-link-foot']\")\n",
    "        if review_more_link:\n",
    "            await review_more_link.scroll_into_view_if_needed()\n",
    "            await review_more_link.click()\n",
    "            break\n",
    "\n",
    "    reviews = []\n",
    "    max_reviews_to_scrape = float(\"inf\")\n",
    "    review_id = 1\n",
    "\n",
    "    while stars_to_scrape <= 5:  # Iterate through 1-star to 5-star reviews\n",
    "        print(f\"Scraping {stars_to_scrape}-star reviews\")\n",
    "\n",
    "        # Select the star rating filter\n",
    "        for _ in range(20):\n",
    "            await page.evaluate(\"window.scrollBy(0, 1000)\")\n",
    "            time.sleep(0.5)\n",
    "\n",
    "            stars_filter_select = await page.query_selector(\"//div[@class='star-rating-select']\")\n",
    "            if stars_filter_select:\n",
    "                await stars_filter_select.click()\n",
    "\n",
    "                # Select the correct star rating\n",
    "                stars_xpath = f\"//li[@aria-labelledby='star-count-dropdown_{stars_to_scrape}']\"\n",
    "                current_star = await page.query_selector(stars_xpath)\n",
    "                if current_star:\n",
    "                    await current_star.click()\n",
    "                else:\n",
    "                    print(f\"Star rating {stars_to_scrape} not found.\")\n",
    "                break\n",
    "\n",
    "        review_index = 1\n",
    "        current_page = 1\n",
    "        review_id = 1\n",
    "\n",
    "        while review_id <= max_reviews_to_scrape:\n",
    "            print(f'Getting review {review_index} on page {current_page}')\n",
    "\n",
    "            current_review = {}\n",
    "\n",
    "            # Name\n",
    "            name_xpath = f\"(//div[@id='cm_cr-review_list']//ul//li)[{review_index}]//*//a[@class='a-profile']/div[2]/span\"\n",
    "            name = await page.query_selector(name_xpath)\n",
    "            if not name:\n",
    "                next_page_button = await page.query_selector(\"//ul[@class='a-pagination'][1]//li[@class='a-last']\")\n",
    "                if next_page_button:\n",
    "                    await next_page_button.click()\n",
    "                    time.sleep(random.randint(1, 3))\n",
    "                    review_index = 1\n",
    "                    current_page += 1\n",
    "                    print(f\"Moving to next page\")\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"Finished scraping {stars_to_scrape}-star reviews.\")\n",
    "                    break\n",
    "\n",
    "            name = await name.inner_text() if name else \"\"\n",
    "            current_review[\"name\"] = name\n",
    "\n",
    "            # Title\n",
    "            title_xpath = f\"(//div[@id='cm_cr-review_list']//ul//li)[{review_index}]//*//a[@data-hook='review-title']//span[2]\"\n",
    "            title = await page.query_selector(title_xpath)\n",
    "            # scroll\n",
    "            # await title.scroll_into_view_if_needed()\n",
    "            title = await title.inner_text() if title else \"\"\n",
    "\n",
    "\n",
    "            title_hash = str(hash(title + name)).replace(\"-\", \"0\")\n",
    "            # current_review[\"review_id\"] = title_hash  \n",
    "            current_review[\"title\"] = title\n",
    "\n",
    "            # Date\n",
    "            date_xpath = f\"(//div[@id='cm_cr-review_list']//ul//li)[{review_index}]//*//span[@data-hook='review-date']\"\n",
    "            date = await page.query_selector(date_xpath)\n",
    "            date = await date.inner_text() if date else \"\"\n",
    "        \n",
    "            # the extracted date is of the format \"Reviewed in the United States on November 10, 2024\"\n",
    "            # we need to extract the date in the format \"November 10, 2024\"\n",
    "            if date:\n",
    "                date = date.split(\"on\")[-1].strip()\n",
    "            else:\n",
    "                date = \"\"\n",
    "            current_review[\"date\"] = date\n",
    "\n",
    "            # Stars\n",
    "            stars_xpath = f\"(//div[@id='cm_cr-review_list']//ul//li)[{review_index}]//*//i[@data-hook='review-star-rating']\"\n",
    "            stars = await page.query_selector(stars_xpath)\n",
    "            stars = await stars.inner_text() if stars else \"\"\n",
    "            current_review[\"stars\"] = str(stars).split(\" \")[0]\n",
    "\n",
    "            # Get Reviewer profile URL  \n",
    "            profile_a_xpath = f\"(//div[@id='cm_cr-review_list']//ul//li)[{review_index}]//*//a[@class='a-profile']\"\n",
    "            profile_a = await page.query_selector(profile_a_xpath)\n",
    "            profile_url = await profile_a.get_attribute(\"href\") if profile_a else \"\"\n",
    "            profile_url = profile_url.split(\"?\")[0] if profile_url else \"\"\n",
    "            current_review[\"profile_url\"] = \"https://www.amazon.com\" + profile_url\n",
    "\n",
    "            # Product Specs\n",
    "            product_specs_xpath = f\"(//div[@id='cm_cr-review_list']//ul//li)[{review_index}]//*//a[@data-hook='format-strip']\"\n",
    "            product_specs = await page.query_selector(product_specs_xpath)\n",
    "            product_specs = await product_specs.inner_text() if product_specs else \"\"\n",
    "            current_review[\"product_specs\"] = product_specs\n",
    "\n",
    "            # Verified Purchase\n",
    "            verified_purchase = await page.query_selector(f\"(//div[@id='cm_cr-review_list']//ul//li)[{review_index}]//*//span[@data-hook='avp-badge']\")\n",
    "            current_review[\"verified_purchase\"] = True if verified_purchase else False\n",
    "\n",
    "            # Read More Button\n",
    "            read_more_button = await page.query_selector(f\"(//div[@id='cm_cr-review_list']//ul//li)[{review_index}]//*//a[@aria-label='Read more of this review']\")\n",
    "            if read_more_button:\n",
    "                await read_more_button.click()\n",
    "                time.sleep(1)  # Ensure content loads\n",
    "\n",
    "            # Helpful Statement\n",
    "            helpful_statement_xpath = f\"(//div[@id='cm_cr-review_list']//ul//li)[{review_index}]//*//span[@data-hook='helpful-vote-statement']\"\n",
    "            helpful_statement = await page.query_selector(helpful_statement_xpath)\n",
    "            helpful_statement = await helpful_statement.inner_text() if helpful_statement else \"\"\n",
    "            current_review[\"helpful_statement\"] = helpful_statement\n",
    "\n",
    "            # Review Text\n",
    "            review_xpath = f\"(//div[@id='cm_cr-review_list']//ul//li)[{review_index}]//*//span[@data-hook='review-body']\"\n",
    "            review = await page.query_selector(review_xpath)\n",
    "            review = await review.inner_text() if review else \"\"\n",
    "            current_review[\"review\"] = review\n",
    "\n",
    "            reviews.append(current_review)\n",
    "            review_index += 1\n",
    "            review_id += 1\n",
    "            time.sleep(random.randint(0, 1))\n",
    "\n",
    "        stars_to_scrape += 1  # Move to the next star rating\n",
    "\n",
    "    review_dictionary[\"reviews\"] = reviews\n",
    "    return review_dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape products with given name\n",
    "for product_to_search in products_to_search:\n",
    "\n",
    "    # product_to_search = product_to_search + ' diapers'\n",
    "\n",
    "    product_reviews = {\n",
    "        \"products\": []\n",
    "    }\n",
    "\n",
    "    product_id = 1\n",
    "\n",
    "    while product_id <= max_items:\n",
    "\n",
    "        # go to product search page\n",
    "        await page.goto(f\"https://www.amazon.com/s?k={product_to_search.replace(' ', '+')}+baby+diaper\")   \n",
    "\n",
    "        # select sort by best sellers\n",
    "        if True:\n",
    "            try:\n",
    "                sort_select_xpath = \"//select[@id='s-result-sort-select']//..//..//..//form\"\n",
    "                sort_select = await page.query_selector(sort_select_xpath)\n",
    "                await sort_select.click()\n",
    "\n",
    "                # best sellers xpath\n",
    "                best_sellers_xpath = \"//a[@id='s-result-sort-select_3']\"\n",
    "                best_sellers = await page.query_selector(best_sellers_xpath)\n",
    "                await best_sellers.click()\n",
    "            except:\n",
    "                print(\"Could not sort by best sellers\")\n",
    "            time.sleep(random.randint(2, 3))\n",
    "\n",
    "        # click on product\n",
    "        product_listing = f\"(//div[@role='listitem'][{product_id}])[1]//a\"\n",
    "        product = await page.query_selector(product_listing)\n",
    "        if product:\n",
    "            await product.click()\n",
    "        else:\n",
    "            print(f\"Product not found: id = {product_id}\")\n",
    "            product_id += 1\n",
    "            continue\n",
    "\n",
    "        # get page url\n",
    "        url = page.url\n",
    "        time.sleep(random.randint(1, 3))\n",
    "\n",
    "        current_product_reviews = await get_reviews(url, product_to_search)\n",
    "        if 'reviews' not in current_product_reviews:\n",
    "            max_items += 1\n",
    "            product_id += 1\n",
    "            continue\n",
    "        \n",
    "        product_reviews['products'].append(current_product_reviews)\n",
    "\n",
    "        # update in json file\n",
    "        save_reviews(product_reviews, filename=f\"{product_to_search}_reviews.json\")\n",
    "\n",
    "        product_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close\n",
    "await browser.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
