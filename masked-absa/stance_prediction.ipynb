{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "\n",
    "model_path = \"google/flan-t5-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model_path = \"Anshul99/finetuned_model_final\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(device) \n",
    "\n",
    "\n",
    "if \"masked_text\" not in df.columns:\n",
    "    raise ValueError(\"The DataFrame must contain a 'masked_text' column.\")\n",
    "\n",
    "df[\"masked_text\"] = df[\"masked_text\"].astype(str)\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    prefix = (\n",
    "        \"Classify stance towards '[MASK]' as 'positive' (supporting/defending '[MASK]') or 'negative' (opposing/criticizing '[MASK]'). Sentence: \"\n",
    "    )\n",
    "    inputs = [prefix + text for text in examples[\"masked_text\"]]\n",
    "    return tokenizer(inputs, truncation=True, padding=\"longest\", max_length=512)\n",
    "\n",
    "dataset = Dataset.from_pandas(df)\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True, remove_columns=dataset.column_names)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n",
    "batch_size = 64  \n",
    "dataloader = DataLoader(tokenized_dataset, batch_size=batch_size, collate_fn=data_collator)\n",
    "stance_predictions = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(dataloader, desc=\"Generating Predictions\"):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        outputs = model.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=2)\n",
    "        decoded_preds = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        stance_predictions.extend(decoded_preds)\n",
    "df[\"stance\"] = stance_predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
